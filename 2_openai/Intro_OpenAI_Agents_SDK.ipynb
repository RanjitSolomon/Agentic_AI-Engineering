{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac3c07d-5f26-4c61-94cb-bb4022703157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9b33bec-0412-4247-87ff-a7fe1782ba18",
   "metadata": {},
   "source": [
    "### asynchronous Python, async IO \n",
    "Lightweight version of multithreading, which does not involve threads at an operating system level and it also does not involve multiprocessing.             \n",
    "This is another way and you can have thousands of these running without consuming resources.       \n",
    "Most of the time, you are waiting on networks and as a result asynchronous code is great.        \n",
    "       \n",
    "async def do_some_processing() -> str:     \n",
    "    # Do some work       \n",
    "    return \"done\"       \n",
    "   \n",
    "result = await do_some_processing()         \n",
    "      \n",
    "Two keywords, async, await      \n",
    "Add \"await\" before calling the function and that function should have \"async\"     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a5535e-9d8c-4e4c-a9d4-2affebf79250",
   "metadata": {},
   "source": [
    "- **Asyncio** provides a lightweight alternative to threading or multiprocessing\n",
    "- Functions defined with **async def** are called **coroutines** , they're special functions that can be paused and resumed.\n",
    "- Calling a coroutine doesn't execute it immediately, it returns a coroutine object\n",
    "- To actually run a coroutine, you must **await** it, which schedules it for execution within an **event loop**\n",
    "- While a coroutine is waiting (e.g. for I/O), the **event loop** can run other coroutines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd37810-aa14-4bf4-aeff-0c7f5003ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def do_some_processing() -> str: \n",
    "    # Do some work \n",
    "    return \"done!\" \n",
    "\n",
    "# Running the function returns a coroutine \n",
    "my_coroutine = do_some_processing()   \n",
    "\n",
    "# awaiting the coroutine returns a result \n",
    "my_result = await my_coroutine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3602d58a-e07c-4d43-86ca-6e2b3168dde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d11e6809-951a-4fbb-8599-b8eb639fa66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = await asyncio.gather (do_some_processing(), do_other_processing(), do_yet_more_processing())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d084a84-7fea-4451-a5b7-7e4d15c8737f",
   "metadata": {},
   "source": [
    "## Introducing OpenAI Agents SDK  \n",
    "- Lightweight and flexible\n",
    "- Stays out of the way\n",
    "- Makes common activities easy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21437b0d-27b8-463c-a42a-651d108ff51e",
   "metadata": {},
   "source": [
    "- **Agents** represent interactions\n",
    "- **Handoffs** represent interactions\n",
    "- **Guardrails** represent controls\n",
    "      \n",
    "#### Three steps \n",
    "1. Create an instance of **Agent**\n",
    "2. Use **with trace()** to track the agent\n",
    "3. Call **runner.run()** to run the agent (an async function/coroutine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce8727-a235-4dfe-9740-4e3a465cbf17",
   "metadata": {},
   "source": [
    "### Documentation \n",
    "<a href=\"https://openai.github.io/openai-agents-python/\">https://openai.github.io/openai-agents-python/</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "805b11f4-0c70-476d-98d9-1e16da8e46bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d63a6d9-0bb6-4bb0-88fd-a2fd0868d243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The usual starting point\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d8678db-1e2a-46a8-a0f1-8e34e44fb990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an agent with name, instructions, model\n",
    "\n",
    "agent = Agent(name=\"Jokester\", instructions=\"You are a joke teller\", model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90383883-b655-471e-90ea-5d54815435c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the autonomous AI agent break up with its partner?  \n",
      "\n",
      "Because it found them too emotionally dependentâ€”it's all about independence, not dependency!\n"
     ]
    }
   ],
   "source": [
    "# Run the joke with Runner.run(agent, prompt) then print final_output\n",
    "\n",
    "with trace(\"Telling a joke\"):\n",
    "    result = await Runner.run(agent, \"Tell a joke about Autonomous AI Agents\")\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b01b799-a05c-44b7-9377-157bef40866b",
   "metadata": {},
   "source": [
    "## Now go and look at the trace\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a36636-2273-43f2-83cc-5487930e8c5e",
   "metadata": {},
   "source": [
    "### Vibe Coding  \n",
    "#### Good vibes \n",
    "Prompt well - ask for short answers and latest APIs for today's date \n",
    "#### Vibe but verify \n",
    "Ask 2 LLMs the same question \n",
    "#### Step up the vibe \n",
    "Ask to break down your request into independently testable steps \n",
    "#### Vibe and Validate \n",
    "Ask an LLM then get another LLM to check   \n",
    "#### Vibe with variety \n",
    "Ask for 3 solutions to the same problem, pick the best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d36c61d-1e4e-4ec2-b3ee-8c8cd48577aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7597707-4739-4c4d-a89c-84fbe1d48464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb8f32-3e8e-46b0-ad72-ce4c66bf10ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfc8f43-5cef-4db8-92ce-5e17cce08984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
