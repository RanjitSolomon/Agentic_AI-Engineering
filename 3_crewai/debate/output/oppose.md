While the concern for regulation of LLMs (Large Language Models) is valid, strict laws may not only be detrimental but also counterproductive in their application. 

Firstly, over-regulation can stifle innovation. LLMs hold the potential to revolutionize industries, enhance creativity, and elevate productivity. Imposing strict laws would create a heavy compliance burden, especially for startups and smaller companies, thereby consolidating power within established corporations. This can lead to a scenario where only a few players dominate the market, limiting diversity in approaches and applications of LLM technology.

Secondly, regulation may hinder the objective of ethical development. Instead of strict prohibitions, a flexible framework that encourages responsible usage while allowing room for growth and experimentation can be more effective. Too rigid a set of laws may lead developers to limit their exploration and risk-taking, thereby slowing advancements in safety and ethical considerations. An environment that fosters collaboration rather than fear of punishment can yield better outcomes in terms of responsibly designed models.

Additionally, the dynamic nature of technology and societal norms makes it difficult for lawmakers to keep pace with rapid advancements in AI. What may seem necessary today could be obsolete tomorrow. Emphasizing a collaborative approach between developers, ethicists, and legislators can lead to adaptable regulations that can evolve alongside advancements rather than locking developers into stringent protocols that may become irrelevant.

Furthermore, existing ethical frameworks and standards could be adapted and applied to the responsible use of LLMs without the need for outright laws. Industry self-regulation and best practices can often address many of the legitimate concerns regarding misinformation, biases, and data privacy more effectively than heavy-handed legislation. Encouraging transparency and ethical standards within the industry can foster accountability while allowing for flexibility and adaptability.

In conclusion, while it is vital to consider the potential risks associated with LLMs, imposing strict laws is not the ideal solution. Instead, encouraging innovation, fostering collaboration, and developing adaptable ethical frameworks can ensure that the benefits of LLMs are realized while addressing the associated risks. Balancing regulation with the urge to innovate can create an environment where technology serves society without being unduly obstructed by regulatory constraints.